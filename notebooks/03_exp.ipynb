{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c425274",
   "metadata": {},
   "source": [
    "### Experiment 3 - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91aacb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, average_precision_score, f1_score, precision_score, recall_score\n",
    "import xgboost as xgb\n",
    "\n",
    "import mlflow\n",
    "import dagshub\n",
    "import logging\n",
    "\n",
    "print('Setup Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6cd8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6362620, 10)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/data.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fa4d62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "X = df.drop(columns=['isFraud', 'isFlaggedFraud'])\n",
    "y = df['isFraud'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a00c4192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"jayast29/ml-fraud-detection\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"jayast29/ml-fraud-detection\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository jayast29/ml-fraud-detection initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository jayast29/ml-fraud-detection initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/4de042f55d7345b0a59cbbb8c1d5f2e9', creation_time=1771652380797, experiment_id='2', last_update_time=1771652380797, lifecycle_stage='active', name='XGBoost', tags={}, workspace='default'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment tracking\n",
    "\n",
    "mlflow.set_tracking_uri('https://dagshub.com/jayast29/ml-fraud-detection.mlflow')\n",
    "dagshub.init(repo_owner='jayast29', repo_name='ml-fraud-detection', mlflow=True)\n",
    "mlflow.set_experiment(\"XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d7d59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 22:51:11,281 - INFO - Starting MLflow run...\n",
      "2026-02-20 22:51:13,094 - INFO - Scaling complete\n",
      "2026-02-20 22:51:56,075 - INFO - Model training complete\n",
      "2026-02-20 22:51:57,823 - INFO - ROC-AUC: 0.9978 | F1: 0.1501\n",
      "2026/02/20 22:51:59 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026-02-20 22:52:17,781 - INFO - MLflow run complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99   1270881\n",
      "           1       0.08      0.95      0.15      1643\n",
      "\n",
      "    accuracy                           0.99   1272524\n",
      "   macro avg       0.54      0.97      0.57   1272524\n",
      "weighted avg       1.00      0.99      0.99   1272524\n",
      "\n",
      "ROC-AUC: 0.9978275942894623\n",
      "Average Precision: 0.8774283106325276\n",
      "üèÉ View run xgboost_v1 at: https://dagshub.com/jayast29/ml-fraud-detection.mlflow/#/experiments/2/runs/4318d3fce26f49c887797bcac0cdd18f\n",
      "üß™ View experiment at: https://dagshub.com/jayast29/ml-fraud-detection.mlflow/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "# MLflow\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logging.getLogger(\"mlflow\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.ERROR)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "with mlflow.start_run(run_name=\"xgboost_v1\"):\n",
    "    \n",
    "    logger.info(\"Starting MLflow run...\")\n",
    "    \n",
    "    # Scale\n",
    "    scaler = RobustScaler()\n",
    "    num_cols = X_train.select_dtypes(include=[np.number]).columns\n",
    "    X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "    X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "    logger.info(\"Scaling complete\")\n",
    "    \n",
    "    # Train\n",
    "    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        tree_method='hist',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='aucpr'\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    logger.info(\"Model training complete\")\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    roc = roc_auc_score(y_test, y_prob)\n",
    "    ap = average_precision_score(y_test, y_prob)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    logger.info(f\"ROC-AUC: {roc:.4f} | F1: {f1:.4f}\")\n",
    "    \n",
    "    # Log params\n",
    "    mlflow.log_param(\"n_estimators\", 200)\n",
    "    mlflow.log_param(\"max_depth\", 6)\n",
    "    mlflow.log_param(\"learning_rate\", 0.1)\n",
    "    mlflow.log_param(\"scale_pos_weight\", scale_pos_weight)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"roc_auc\", roc)\n",
    "    mlflow.log_metric(\"average_precision\", ap)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.xgboost.log_model(model, \"model\")\n",
    "    logger.info(\"MLflow run complete\")\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"ROC-AUC:\", roc)\n",
    "    print(\"Average Precision:\", ap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1a47a0",
   "metadata": {},
   "source": [
    "XGBoost delivers the best overall balance across all metrics. It achieves the highest recall of 0.95, catching 95% of all fraudulent transactions on the full dataset. However, precision drops to 0.08, indicating a high false positive rate. With ROC-AUC and AUPRC as primary metrics, XGBoost is selected as the final model due to its superior fraud detection capability - in banking fraud, missing real fraud is far more costly than investigating false alerts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
